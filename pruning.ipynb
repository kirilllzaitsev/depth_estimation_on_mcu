{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n",
      "WARNING:tensorflow:From /home/master/.conda/envs/sc/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential, save_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import tempfile\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import numpy as np\n",
    "\n",
    "# Model configuration\n",
    "img_width, img_height = 28, 28\n",
    "batch_size = 250\n",
    "no_classes = 10\n",
    "validation_split = 0.2\n",
    "verbosity = 1\n",
    "pruning_epochs = 30\n",
    "\n",
    "# Load MNIST dataset\n",
    "(input_train, target_train), (input_test, target_test) = mnist.load_data()\n",
    "input_shape = (img_width, img_height, 1)\n",
    "\n",
    "# Reshape data for ConvNet\n",
    "input_train = input_train.reshape(input_train.shape[0], img_width, img_height, 1)\n",
    "input_test = input_test.reshape(input_test.shape[0], img_width, img_height, 1)\n",
    "input_shape = (img_width, img_height, 1)\n",
    "\n",
    "# Parse numbers as floats\n",
    "input_train = input_train.astype('float32')\n",
    "input_test = input_test.astype('float32')\n",
    "\n",
    "# Normalize [0, 255] into [0, 1]\n",
    "input_train = input_train / 255\n",
    "input_test = input_test / 255\n",
    "\n",
    "# Convert target vectors to categorical targets\n",
    "target_train = tensorflow.keras.utils.to_categorical(target_train, no_classes)\n",
    "target_test = tensorflow.keras.utils.to_categorical(target_test, no_classes)\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(no_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=tensorflow.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tensorflow.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Load functionality for adding pruning wrappers\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Finish pruning after 10 epochs\n",
    "num_images = input_train.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * pruning_epochs\n",
    "\n",
    "# Define pruning configuration\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(target_sparsity=0.875,\n",
    "                                                               begin_step=0.2*end_step,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target_sparsity': 0.875, 'begin_step': 1152.0, 'end_step': 5760}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(target_sparsity=0.875,\n",
    "                                                               begin_step=0.2*end_step,\n",
    "                                                               end_step=end_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-19 12:31:37.923454: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/prune_low_magnitude_dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/192 [==============================] - 4s 5ms/step - loss: 0.3515 - accuracy: 0.8932 - val_loss: 0.0906 - val_accuracy: 0.9749\n",
      "Epoch 2/30\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.0977 - accuracy: 0.9696 - val_loss: 0.0665 - val_accuracy: 0.9817\n",
      "Epoch 3/30\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.0687 - accuracy: 0.9790 - val_loss: 0.0634 - val_accuracy: 0.9812\n",
      "Epoch 4/30\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.0539 - accuracy: 0.9828 - val_loss: 0.0462 - val_accuracy: 0.9873\n",
      "Epoch 5/30\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.0443 - accuracy: 0.9858 - val_loss: 0.0397 - val_accuracy: 0.9886\n",
      "Epoch 6/30\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.0492 - accuracy: 0.9846 - val_loss: 2.1978 - val_accuracy: 0.3038\n",
      "Epoch 7/30\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.4333 - accuracy: 0.8985 - val_loss: 0.0750 - val_accuracy: 0.9800\n",
      "Epoch 8/30\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.1005 - accuracy: 0.9691 - val_loss: 0.0547 - val_accuracy: 0.9849\n",
      "Epoch 9/30\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.0797 - accuracy: 0.9753 - val_loss: 0.0482 - val_accuracy: 0.9867\n",
      "Epoch 10/30\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.0706 - accuracy: 0.9776 - val_loss: 0.0451 - val_accuracy: 0.9874\n",
      "Epoch 11/30\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.0645 - accuracy: 0.9799 - val_loss: 0.0426 - val_accuracy: 0.9877\n",
      "Epoch 12/30\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.0588 - accuracy: 0.9809 - val_loss: 0.0400 - val_accuracy: 0.9892\n",
      "Epoch 13/30\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.0559 - accuracy: 0.9822 - val_loss: 0.0393 - val_accuracy: 0.9892\n",
      "Epoch 14/30\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.0513 - accuracy: 0.9839 - val_loss: 0.0373 - val_accuracy: 0.9898\n",
      "Epoch 15/30\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.0501 - accuracy: 0.9837 - val_loss: 0.0365 - val_accuracy: 0.9898\n",
      "Epoch 16/30\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.0472 - accuracy: 0.9850 - val_loss: 0.0366 - val_accuracy: 0.9900\n",
      "Epoch 17/30\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.0447 - accuracy: 0.9852 - val_loss: 0.0360 - val_accuracy: 0.9899\n",
      "Epoch 18/30\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.0428 - accuracy: 0.9859 - val_loss: 0.0358 - val_accuracy: 0.9902\n",
      "Epoch 19/30\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.0431 - accuracy: 0.9864 - val_loss: 0.0355 - val_accuracy: 0.9903\n",
      "Epoch 20/30\n",
      "192/192 [==============================] - 1s 4ms/step - loss: 0.0418 - accuracy: 0.9859 - val_loss: 0.0338 - val_accuracy: 0.9908\n",
      "Epoch 21/30\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.0399 - accuracy: 0.9871 - val_loss: 0.0341 - val_accuracy: 0.9909\n",
      "Epoch 22/30\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.0380 - accuracy: 0.9878 - val_loss: 0.0335 - val_accuracy: 0.9908\n",
      "Epoch 23/30\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.0383 - accuracy: 0.9872 - val_loss: 0.0319 - val_accuracy: 0.9909\n",
      "Epoch 24/30\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.0362 - accuracy: 0.9881 - val_loss: 0.0323 - val_accuracy: 0.9912\n",
      "Epoch 25/30\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.0349 - accuracy: 0.9887 - val_loss: 0.0323 - val_accuracy: 0.9914\n",
      "Epoch 26/30\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.0341 - accuracy: 0.9891 - val_loss: 0.0314 - val_accuracy: 0.9915\n",
      "Epoch 27/30\n",
      "192/192 [==============================] - 1s 4ms/step - loss: 0.0338 - accuracy: 0.9898 - val_loss: 0.0320 - val_accuracy: 0.9912\n",
      "Epoch 28/30\n",
      "192/192 [==============================] - 1s 4ms/step - loss: 0.0338 - accuracy: 0.9883 - val_loss: 0.0310 - val_accuracy: 0.9918\n",
      "Epoch 29/30\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.0339 - accuracy: 0.9889 - val_loss: 0.0311 - val_accuracy: 0.9912\n",
      "Epoch 30/30\n",
      "192/192 [==============================] - 1s 4ms/step - loss: 0.0300 - accuracy: 0.9899 - val_loss: 0.0313 - val_accuracy: 0.9913\n",
      "Pruned CNN - Test loss: 0.026395482942461967 / Test accuracy: 0.9909999966621399\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Pruned model saved: /tmp/tmph1w2167i.h5\n",
      "Size of gzipped pruned Keras model: 387977.00 bytes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Recompile the model\n",
    "model_for_pruning.compile(loss=tensorflow.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tensorflow.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Model callbacks\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep()\n",
    "]\n",
    "\n",
    "# Fitting data\n",
    "model_for_pruning.fit(input_train, target_train,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=pruning_epochs,\n",
    "                      verbose=verbosity,\n",
    "                      callbacks=callbacks,\n",
    "                      validation_split=validation_split)\n",
    "\n",
    "# Generate generalization metrics\n",
    "score_pruned = model_for_pruning.evaluate(input_test, target_test, verbose=0)\n",
    "print(f'Pruned CNN - Test loss: {score_pruned[0]} / Test accuracy: {score_pruned[1]}')\n",
    "\n",
    "# Export the model\n",
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
    "save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
    "print(f'Pruned model saved: {pruned_keras_file}')\n",
    "\n",
    "# Measuring the size of your pruned model\n",
    "# (source: https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras#fine-tune_pre-trained_model_with_pruning)\n",
    "\n",
    "def get_gzipped_model_size(file):\n",
    "  # Returns size of gzipped model, in bytes.\n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)\n",
    "\n",
    "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

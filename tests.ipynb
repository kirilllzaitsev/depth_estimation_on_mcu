{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: NYU Depth V2\n",
      "# of train images: 50688\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from nyuv2_torch_ds_adapter import nyudepthv2\n",
    "data, args = None, argparse.Namespace()\n",
    "args.truncate_testset = False\n",
    "# args.target_size = (64, 64)\n",
    "args.crop_size = (640, 480)\n",
    "args.target_size = (64, 64)\n",
    "# args.target_size = (480,640)\n",
    "args.out_fold_ratio = 1\n",
    "args.is_maxim = False\n",
    "nyuv2_ds = nyudepthv2(\n",
    "            data_path=\"/media/master/text/cv_data/nyuv2/nyu_data/data\",\n",
    "            filenames_path=\"/media/master/text/cv_data/nyuv2/nyu_data/data\",\n",
    "            args=args,\n",
    "            is_train=True,\n",
    "            crop_size=args.crop_size,\n",
    "            scale_size=args.target_size,\n",
    "            fold_ratio=args.out_fold_ratio,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 64, 3]), TensorShape([64, 64]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "nyuv2_loader = torch.utils.data.DataLoader(\n",
    "    nyuv2_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    ")\n",
    "def generator():\n",
    "    # for images, labels in nyuv2_loader:\n",
    "    for sample in nyuv2_ds:\n",
    "        # Yield data batch-by-batch\n",
    "        yield sample\n",
    "        # yield images.numpy(), labels.numpy()\n",
    "\n",
    "# Use output_signature to specify the output format and shapes\n",
    "output_signature = (\n",
    "    tf.TensorSpec(shape=(64, 64, 3), dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=(64, 64), dtype=tf.float32)\n",
    ")\n",
    "\n",
    "# Create a tf.data.Dataset from generator\n",
    "tf_dataset = tf.data.Dataset.from_generator(generator, output_signature=output_signature)\n",
    "x=next(iter(tf_dataset))\n",
    "x[0].shape, x[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=next(iter(tf_dataset.shuffle(100).skip(100).batch(2).take(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: NYU Depth V2\n",
      "# of train images: 50688\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from nyuv2_torch_ds_adapter import nyudepthv2\n",
    "# Assuming `dataset` is your original PyTorch dataset\n",
    "dataset=nyudepthv2(\n",
    "        data_path=\"/media/master/text/cv_data/nyuv2/nyu_data/data\",\n",
    "        filenames_path=\"/media/master/text/cv_data/nyuv2/nyu_data/data\",\n",
    "        args=args,\n",
    "        is_train=True,\n",
    "        crop_size=args.crop_size,\n",
    "        scale_size=args.target_size,\n",
    "        fold_ratio=args.out_fold_ratio,\n",
    "    )\n",
    "# Define the size of the validation set\n",
    "val_size = int(0.2 * len(dataset))  # 20% of the dataset\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_dataset, val_dataset = random_split(dataset, [len(dataset) - val_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40551"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the size of the training and testing subsets (e.g., 80% for training, 20% for testing)\n",
    "dataset_size = len(nyuv2_ds)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "# Shuffle the dataset\n",
    "dataset_shuffled = tf_dataset.shuffle(100)\n",
    "\n",
    "# Split the dataset into train and test subsets\n",
    "train_dataset = dataset_shuffled.take(train_size)\n",
    "test_dataset = dataset_shuffled.skip(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 64, 64, 3), dtype=float32, numpy=\n",
       " array([[[[251., 251., 251.],\n",
       "          [251., 255., 255.],\n",
       "          [252., 255., 255.],\n",
       "          ...,\n",
       "          [255., 253., 250.],\n",
       "          [251., 250., 248.],\n",
       "          [255., 254., 255.]],\n",
       " \n",
       "         [[255., 253., 255.],\n",
       "          [140., 143., 156.],\n",
       "          [142., 150., 172.],\n",
       "          ...,\n",
       "          [ 35.,  18.,   4.],\n",
       "          [ 19.,  16.,   5.],\n",
       "          [253., 253., 251.]],\n",
       " \n",
       "         [[255., 254., 255.],\n",
       "          [145., 149., 158.],\n",
       "          [150., 152., 166.],\n",
       "          ...,\n",
       "          [ 33.,  20.,   4.],\n",
       "          [ 15.,  12.,   5.],\n",
       "          [255., 253., 250.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[252., 254., 255.],\n",
       "          [ 41.,  56.,  88.],\n",
       "          [ 31.,  34.,  71.],\n",
       "          ...,\n",
       "          [ 18.,  22.,   9.],\n",
       "          [ 18.,  35.,  15.],\n",
       "          [255., 254., 255.]],\n",
       " \n",
       "         [[251., 254., 255.],\n",
       "          [ 39.,  60.,  80.],\n",
       "          [ 59.,  66.,  88.],\n",
       "          ...,\n",
       "          [ 14.,  23.,   5.],\n",
       "          [ 18.,  32.,   6.],\n",
       "          [254., 255., 254.]],\n",
       " \n",
       "         [[253., 253., 254.],\n",
       "          [252., 255., 255.],\n",
       "          [252., 254., 255.],\n",
       "          ...,\n",
       "          [254., 254., 251.],\n",
       "          [253., 255., 251.],\n",
       "          [250., 248., 249.]]],\n",
       " \n",
       " \n",
       "        [[[246., 249., 249.],\n",
       "          [251., 255., 255.],\n",
       "          [251., 254., 255.],\n",
       "          ...,\n",
       "          [251., 255., 254.],\n",
       "          [253., 252., 249.],\n",
       "          [255., 254., 254.]],\n",
       " \n",
       "         [[250., 251., 255.],\n",
       "          [147., 162., 182.],\n",
       "          [146., 158., 173.],\n",
       "          ...,\n",
       "          [ 81.,  86.,  80.],\n",
       "          [114., 111.,  97.],\n",
       "          [255., 252., 253.]],\n",
       " \n",
       "         [[253., 253., 255.],\n",
       "          [139., 152., 171.],\n",
       "          [141., 154., 171.],\n",
       "          ...,\n",
       "          [109., 114., 113.],\n",
       "          [124., 118.,  98.],\n",
       "          [254., 252., 252.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[250., 254., 255.],\n",
       "          [ 89.,  98., 102.],\n",
       "          [ 90.,  93., 104.],\n",
       "          ...,\n",
       "          [ 83.,  83.,  57.],\n",
       "          [ 87.,  92.,  73.],\n",
       "          [252., 252., 252.]],\n",
       " \n",
       "         [[253., 254., 255.],\n",
       "          [ 97., 102., 120.],\n",
       "          [ 99., 105., 121.],\n",
       "          ...,\n",
       "          [ 91.,  89.,  74.],\n",
       "          [ 85.,  86.,  80.],\n",
       "          [253., 253., 253.]],\n",
       " \n",
       "         [[250., 248., 249.],\n",
       "          [253., 254., 255.],\n",
       "          [255., 254., 255.],\n",
       "          ...,\n",
       "          [255., 255., 252.],\n",
       "          [255., 255., 250.],\n",
       "          [249., 249., 249.]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 64, 64), dtype=float32, numpy=\n",
       " array([[[0.075     , 0.075     , 0.076     , ..., 0.14250001,\n",
       "          0.141     , 0.14      ],\n",
       "         [0.07425   , 0.075     , 0.075     , ..., 0.151     ,\n",
       "          0.151     , 0.14      ],\n",
       "         [0.074     , 0.07475001, 0.075     , ..., 0.151     ,\n",
       "          0.151     , 0.139     ],\n",
       "         ...,\n",
       "         [0.036     , 0.032     , 0.032     , ..., 0.032     ,\n",
       "          0.032     , 0.05      ],\n",
       "         [0.035     , 0.029875  , 0.027     , ..., 0.032     ,\n",
       "          0.032     , 0.05      ],\n",
       "         [0.035     , 0.034     , 0.033     , ..., 0.047     ,\n",
       "          0.048     , 0.049     ]],\n",
       " \n",
       "        [[0.131     , 0.132     , 0.133     , ..., 0.169     ,\n",
       "          0.167     , 0.165     ],\n",
       "         [0.13      , 0.131     , 0.132     , ..., 0.1695    ,\n",
       "          0.17      , 0.164     ],\n",
       "         [0.129     , 0.129     , 0.13      , ..., 0.17      ,\n",
       "          0.17      , 0.163     ],\n",
       "         ...,\n",
       "         [0.061     , 0.057     , 0.0555    , ..., 0.053     ,\n",
       "          0.054     , 0.064     ],\n",
       "         [0.06      , 0.055     , 0.054     , ..., 0.054     ,\n",
       "          0.054     , 0.063     ],\n",
       "         [0.059     , 0.057     , 0.055     , ..., 0.06      ,\n",
       "          0.061     , 0.062     ]]], dtype=float32)>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset.batch(2).take(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

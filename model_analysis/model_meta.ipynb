{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/master/.conda/envs/sc/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/master/.conda/envs/sc/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/master/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c5dda1efd7451ea30f6fb23f0a71a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fvcore.nn import FlopCountAnalysis\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 480, 640])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/master/.conda/envs/sc/lib/python3.9/site-packages/torch/nn/functional.py:3908: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  (torch.floor((input.size(i + 2).float() * torch.tensor(scale_factors[i], dtype=torch.float32)).float()))\n",
      "/home/master/.conda/envs/sc/lib/python3.9/site-packages/torchvision/ops/boxes.py:157: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  boxes_x = torch.min(boxes_x, torch.tensor(width, dtype=boxes.dtype, device=boxes.device))\n",
      "/home/master/.conda/envs/sc/lib/python3.9/site-packages/torchvision/ops/boxes.py:159: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  boxes_y = torch.min(boxes_y, torch.tensor(height, dtype=boxes.dtype, device=boxes.device))\n",
      "/home/master/.conda/envs/sc/lib/python3.9/site-packages/torchvision/models/detection/transform.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(s, dtype=torch.float32, device=boxes.device)\n",
      "/home/master/.conda/envs/sc/lib/python3.9/site-packages/torchvision/models/detection/transform.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  / torch.tensor(s_orig, dtype=torch.float32, device=boxes.device)\n",
      "Unsupported operator aten::sub encountered 72 time(s)\n",
      "Unsupported operator aten::div encountered 14 time(s)\n",
      "Unsupported operator aten::_shape_as_tensor encountered 6 time(s)\n",
      "Unsupported operator aten::min encountered 11 time(s)\n",
      "Unsupported operator aten::reciprocal encountered 2 time(s)\n",
      "Unsupported operator aten::mul encountered 206 time(s)\n",
      "Unsupported operator aten::ceil encountered 2 time(s)\n",
      "Unsupported operator aten::pad encountered 1 time(s)\n",
      "Unsupported operator aten::add encountered 136 time(s)\n",
      "Unsupported operator aten::rsqrt encountered 53 time(s)\n",
      "Unsupported operator aten::max_pool2d encountered 2 time(s)\n",
      "Unsupported operator aten::add_ encountered 19 time(s)\n",
      "Unsupported operator aten::fill_ encountered 10 time(s)\n",
      "Unsupported operator aten::meshgrid encountered 5 time(s)\n",
      "Unsupported operator aten::exp encountered 4 time(s)\n",
      "Unsupported operator aten::expand_as encountered 2 time(s)\n",
      "Unsupported operator aten::topk encountered 5 time(s)\n",
      "Unsupported operator aten::sigmoid encountered 1 time(s)\n",
      "Unsupported operator aten::where encountered 12 time(s)\n",
      "Unsupported operator prim::CallFunction encountered 2 time(s)\n",
      "Unsupported operator aten::sqrt encountered 1 time(s)\n",
      "Unsupported operator aten::log2 encountered 1 time(s)\n",
      "Unsupported operator torchvision::roi_align encountered 4 time(s)\n",
      "Unsupported operator aten::scatter encountered 4 time(s)\n",
      "Unsupported operator aten::softmax encountered 1 time(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "177610246144"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = \"/media/master/wext/msc_studies/second_semester/microcontrollers/exercices/7/Exercise7/jupyter/test.png\"\n",
    "img = Image.open(img_path).convert(\"RGB\")\n",
    "transform = T.Compose([T.ToTensor()])\n",
    "img = transform(img)\n",
    "# pred = model([img])\n",
    "model.eval()\n",
    "flops = FlopCountAnalysis(model, [img])\n",
    "flops.total()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flops_resnet50=177_610_246_144"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
